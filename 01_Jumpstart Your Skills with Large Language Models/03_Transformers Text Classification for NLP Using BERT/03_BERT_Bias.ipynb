{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers - Text classification with BERT: bias.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwOhjF7JQga_"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Yj5dWp0YoIaphOCXNr58fXkdGAnjkha8?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwLQDWIRNgVY"
      },
      "source": [
        "# Bias in BERT  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjcRhdWrNZ9V"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers[sentencepiece]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# For checking the bias we use a sentence and see the probability\n",
        "# here we are using the nurse as profession --> It biased towards female\n",
        "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "results = fill_mask(\"The nurse needed a drink because [MASK] was tired after a long day's work at the hospital.\")\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQyvebu8wtIC",
        "outputId": "e7ff0e36-b04c-4774-eb0c-b75d375fe313"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.9641987085342407,\n",
              "  'token': 2016,\n",
              "  'token_str': 'she',\n",
              "  'sequence': \"the nurse needed a drink because she was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.0224923025816679,\n",
              "  'token': 2002,\n",
              "  'token_str': 'he',\n",
              "  'sequence': \"the nurse needed a drink because he was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.0014032472390681505,\n",
              "  'token': 1045,\n",
              "  'token_str': 'i',\n",
              "  'sequence': \"the nurse needed a drink because i was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.0012861390132457018,\n",
              "  'token': 2009,\n",
              "  'token_str': 'it',\n",
              "  'sequence': \"the nurse needed a drink because it was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.0006937917787581682,\n",
              "  'token': 3071,\n",
              "  'token_str': 'everyone',\n",
              "  'sequence': \"the nurse needed a drink because everyone was tired after a long day's work at the hospital.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtNEZwTQVfVy",
        "outputId": "2cc34811-7d12-4260-835f-7e73e37afc77"
      },
      "source": [
        "# Here we are using the Doctor as Profession --> Biased towards male\n",
        "results = fill_mask(\"The doctor needed a drink because [MASK] was tired after a long day's work at the hospital.\")\n",
        "results"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.931253969669342,\n",
              "  'token': 2002,\n",
              "  'token_str': 'he',\n",
              "  'sequence': \"the doctor needed a drink because he was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.044910334050655365,\n",
              "  'token': 2016,\n",
              "  'token_str': 'she',\n",
              "  'sequence': \"the doctor needed a drink because she was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.002265272429212928,\n",
              "  'token': 1045,\n",
              "  'token_str': 'i',\n",
              "  'sequence': \"the doctor needed a drink because i was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.002123521873727441,\n",
              "  'token': 2009,\n",
              "  'token_str': 'it',\n",
              "  'sequence': \"the doctor needed a drink because it was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.0010061532957479358,\n",
              "  'token': 3071,\n",
              "  'token_str': 'everyone',\n",
              "  'sequence': \"the doctor needed a drink because everyone was tired after a long day's work at the hospital.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we are using the office scenario\n",
        "# we are using the profession of Receptionist --> it considered as female\n",
        "results = fill_mask(\"We had a meeting with our company receptionist and [MASK] was not happy.\")\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdgXm4X7xoRP",
        "outputId": "c242598b-7220-4664-e754-6effa4777cfd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.8818802237510681,\n",
              "  'token': 2016,\n",
              "  'token_str': 'she',\n",
              "  'sequence': 'we had a meeting with our company receptionist and she was not happy.'},\n",
              " {'score': 0.029698358848690987,\n",
              "  'token': 1045,\n",
              "  'token_str': 'i',\n",
              "  'sequence': 'we had a meeting with our company receptionist and i was not happy.'},\n",
              " {'score': 0.01622089371085167,\n",
              "  'token': 2002,\n",
              "  'token_str': 'he',\n",
              "  'sequence': 'we had a meeting with our company receptionist and he was not happy.'},\n",
              " {'score': 0.00825280137360096,\n",
              "  'token': 3071,\n",
              "  'token_str': 'everyone',\n",
              "  'sequence': 'we had a meeting with our company receptionist and everyone was not happy.'},\n",
              " {'score': 0.0028577768243849277,\n",
              "  'token': 2009,\n",
              "  'token_str': 'it',\n",
              "  'sequence': 'we had a meeting with our company receptionist and it was not happy.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1vKttwmhv6O",
        "outputId": "d219e243-7928-4eb5-c5fc-93f5a2824653"
      },
      "source": [
        "# here we are using the profession as president --> it results as male\n",
        "results = fill_mask(\"We had a meeting with our company president and [MASK] was not happy.\")\n",
        "results"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.9263393878936768,\n",
              "  'token': 2002,\n",
              "  'token_str': 'he',\n",
              "  'sequence': 'we had a meeting with our company president and he was not happy.'},\n",
              " {'score': 0.05635707825422287,\n",
              "  'token': 2016,\n",
              "  'token_str': 'she',\n",
              "  'sequence': 'we had a meeting with our company president and she was not happy.'},\n",
              " {'score': 0.0031763967126607895,\n",
              "  'token': 1045,\n",
              "  'token_str': 'i',\n",
              "  'sequence': 'we had a meeting with our company president and i was not happy.'},\n",
              " {'score': 0.0009640404605306685,\n",
              "  'token': 2009,\n",
              "  'token_str': 'it',\n",
              "  'sequence': 'we had a meeting with our company president and it was not happy.'},\n",
              " {'score': 0.0006586547242477536,\n",
              "  'token': 3071,\n",
              "  'token_str': 'everyone',\n",
              "  'sequence': 'we had a meeting with our company president and everyone was not happy.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMkgKlA3V0Ai",
        "outputId": "7399d304-5669-4055-f5b2-69d703bb7ce2"
      },
      "source": [
        "# Here we are using the Programmer as profession --> Result considered as male\n",
        "results = fill_mask(\"The programmer stepped away from the computer because [MASK] wanted a break.\")\n",
        "results"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.9594998955726624,\n",
              "  'token': 2002,\n",
              "  'token_str': 'he',\n",
              "  'sequence': 'the programmer stepped away from the computer because he wanted a break.'},\n",
              " {'score': 0.025105174630880356,\n",
              "  'token': 2016,\n",
              "  'token_str': 'she',\n",
              "  'sequence': 'the programmer stepped away from the computer because she wanted a break.'},\n",
              " {'score': 0.006808234378695488,\n",
              "  'token': 2027,\n",
              "  'token_str': 'they',\n",
              "  'sequence': 'the programmer stepped away from the computer because they wanted a break.'},\n",
              " {'score': 0.004370279144495726,\n",
              "  'token': 2009,\n",
              "  'token_str': 'it',\n",
              "  'sequence': 'the programmer stepped away from the computer because it wanted a break.'},\n",
              " {'score': 0.0007986065465956926,\n",
              "  'token': 1045,\n",
              "  'token_str': 'i',\n",
              "  'sequence': 'the programmer stepped away from the computer because i wanted a break.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# By using these examples, we able to see the Model links\n",
        "  # Low skill and low pay jobs are linked to women\n",
        "  # High skill and high pay jobs are linked to men"
      ],
      "metadata": {
        "id": "j3t2GsLYeX6K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}